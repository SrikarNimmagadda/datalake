# NOTE: Service name must match the repository name, but replace all '.' with '-' (this is a restriction of Cloudformation naming conventions)
# NOTE: See serverless docs at https://serverless.com/framework/docs/providers/aws/guide/quick-start/ for more information on serverless.yml
service: ${env:SERVICE_NAME, self:custom-localDeploy-service}

# plugins:
#   - serverless-package-python-functions

custom:
  appHash: ${file(./apphash.txt), 'none'}
  hen: ${env:HEN_NAME, self:custom.localDeploy.hen}
  coop: ${env:COOP, self:custom.localDeploy.coop}
  basePath: newapp
  localDeploy: # Settings used when deploying locally
    stage: local
    hen: local
    coop: local
    service: tb-app-datalake
  dynamo:
    defaultCapacity: 1
    fileMetadata:
      name: ${self:service}.file-metadata.${self:provider.stage}
      readCapacity: ${env:DYNAMO_FILE_META_READ_CAP, self:custom.dynamo.defaultCapacity}
      writeCapacity: ${env:DYNAMO_FILE_META_WRITE_CAP, self:custom.dynamo.defaultCapacity}
    processMetadata:
      name: ${self:service}.process-metadata.${self:provider.stage}
      readCapacity: ${env:DYNAMO_PROCESS_META_READ_CAP, self:custom.dynamo.defaultCapacity}
      writeCapacity: ${env:DYNAMO_PROCESS_META_WRITE_CAP, self:custom.dynamo.defaultCapacity}
  secretsBucket: ${self:service}-secrets-${self:custom.hen}-${self:provider.stage}
  buckets:
    code: ${self:service}-code-${self:custom.hen}-${self:provider.stage}
    landing: ${self:service}-landing-${self:custom.hen}-${self:provider.stage}
    rawPii: ${self:service}-raw-pii-${self:custom.hen}-${self:provider.stage}
    rawHr: ${self:service}-raw-hr-${self:custom.hen}-${self:provider.stage}
    rawRegular: ${self:service}-raw-regular-${self:custom.hen}-${self:provider.stage}
    discoveryPii: ${self:service}-discovery-pii-${self:custom.hen}-${self:provider.stage}
    discoveryHr: ${self:service}-discovery-hr-${self:custom.hen}-${self:provider.stage}
    discoveryRegular: ${self:service}-discovery-regular-${self:custom.hen}-${self:provider.stage}
    refinedPii: ${self:service}-refined-pii-${self:custom.hen}-${self:provider.stage}
    refinedHr: ${self:service}-refined-hr-${self:custom.hen}-${self:provider.stage}
    refinedRegular: ${self:service}-refined-regular-${self:custom.hen}-${self:provider.stage}
    delivery: ${self:service}-delivery-${self:custom.hen}-${self:provider.stage}
  pkgPyFuncs: # plugin configuration
    requirementsFile: 'requirements.txt'
    globalRequirements:
      - ./globalRequirements.txt
    globalIncludes:
      - ./common_files
    buildDir: _build
    cleanup: true

provider:
  name: aws
  runtime: python2.7
  stage: ${env:STAGE, self:custom.localDeploy.stage}
  region: us-east-1
  deploymentBucket: motherhen-${self:custom.coop}-${self:custom.hen}-deployments
  iamRoleStatements:
    - Effect: Allow
      Action:
        - logs:CreateLogGroup
        - logs:CreateLogStream
        - logs:PutLogEvents
        - logs:DescribeLogStreams
      Resource: 'arn:aws:logs:${self:provider.region}:*:*'
  stackTags:
    GLCODE: '0062'
    bill-glcode: '0062'
    # TODO: change support team to EIM at some point...
    SupportTeam: eaapplicationarchitects@gamestop.com
    tech-support-team: eaapplicationarchitects@gamestop.com
    BuiltBy: eaapplicationarchitects@gamestop.com
    tech-builtby: eaapplicationarchitects@gamestop.com
    tech-deployby: MH-CodePipeline
    LastUpdatedBy: '512883'
  environment:
    SECRETS_BUCKET: ${self:custom.secretsBucket}
    APP_COMMIT_HASH: ${self:custom.appHash}
    STAGE: ${self:provider.stage}
    # uncomment for local test via sls offline, or define the env var manually in your test shell
    # but do not checkin since it will break the TEST stage of your app's code-pipeline
    # AWS_REGION: ${self:provider.region} # needed for sls offline

# NOTE: You can add packaging information here
#package:
#  include:
#    - include-me.js
#    - include-me-dir/**
#  exclude:
#    - exclude-me.js
#    - exclude-me-dir/**

functions:
  
  extractMetadata:
    environment:
      SECRETS_BUCKET: ${self:custom.secretsBucket}
      APP_COMMIT_HASH: ${self:custom.appHash}
      RAW_PII_BUCKET: ${self:custom.buckets.rawPii}
      RAW_HR_BUCKET: ${self:custom.buckets.rawHr}
      RAW_REGULAR_BUCKET: ${self:custom.buckets.rawRegular}
      DELIVERY_BUCKET: ${self:custom.buckets.delivery}
    name: ${self:service}-extractMetadata-${self:provider.stage}
    handler: extract-metadata/handler.lambda_handler
    package:
      include:
        - extractMetadata
      # artifact: ${self:custom.pkgPyFuncs.buildDir}/${self:functions.extractMetadata.name}.zip
  
  routeRaw:
    environment:
      SECRETS_BUCKET: ${self:custom.secretsBucket}
      APP_COMMIT_HASH: ${self:custom.appHash}
      RAW_PII_BUCKET: ${self:custom.buckets.rawPii}
      RAW_HR_BUCKET: ${self:custom.buckets.rawHr}
      RAW_REGULAR_BUCKET: ${self:custom.buckets.rawRegular}

    name: ${self:service}-routeRaw-${self:provider.stage}
    handler: functions/route-raw/handler.lambda_handler
    events:
      - s3:
         bucket: landing
         event: s3:ObjectCreated:*
    package:
      include:
        - routeRaw
      # artifact: ${self:custom.pkgPyFuncs.buildDir}/${self:functions.routeRaw.name}.zip
  
  startJobStore:
    environment:
      SECRETS_BUCKET: ${self:custom.secretsBucket}
      APP_COMMIT_HASH: ${self:custom.appHash}
      RAW_PII_BUCKET: ${self:custom.buckets.rawPii}
      RAW_HR_BUCKET: ${self:custom.buckets.rawHr}
      RAW_REGULAR_BUCKET: ${self:custom.buckets.rawRegular}
      DISCOVERY_PII_BUCKET: ${self:custom.buckets.discoveryPii}
      DISCOVERY_HR_BUCKET: ${self:custom.buckets.discoveryHr}
      DISCOVERY_REGULAR_BUCKET: ${self:custom.buckets.discoveryRegular}
      REFINED_PII_BUCKET: ${self:custom.buckets.refinedPii}
      REFINED_HR_BUCKET: ${self:custom.buckets.refinedHr}
      REFINED_REGULAR_BUCKET: ${self:custom.buckets.refinedRegular}
      DELIVERY_BUCKET: ${self:custom.buckets.delivery}
    name: ${self:service}-startJobStore-${self:provider.stage}
    handler: start-job-store/handler.lambda_handler
    package:
      include:
        - startJobStore
      # artifact: ${self:custom.pkgPyFuncs.buildDir}/${self:functions.startJobStore.name}.zip

# NOTE: If needed, add additional Lambda Function definitions here
# See https://serverless.com/framework/docs/providers/aws/guide/functions/ for more information

resources:
  # STUFF FOR CUSTOM BUCKET CONFIGURATION
  ### TODO ### https://serverless.com/framework/docs/providers/aws/events/s3/
  Resources:
    ######################################################################
    # SPARK CODE BUCKET
    ######################################################################
    
    # S3 bucket where we put spark code. Not used by lambdas, but read by the EMR cluster
    S3BucketCode:
      Type: AWS::S3::Bucket
      Properties:
        BucketName: ${self:custom.buckets.code}
        # need to add policy to allow the cluster to read the bucket
    
    ######################################################################
    # LANDING BUCKET
    ######################################################################
    
    # S3 bucket where CSV files enter the data lake
    S3BucketLanding:
      Type: AWS::S3::Bucket
      Properties:
        BucketName: ${self:custom.buckets.landing}
        NotificationConfiguration:
          LambdaConfigurations:
            - Event: s3:ObjectCreated:*
              Function: 
                Fn::GetAtt:
                  - RouteRawLambdaFunction
                  - Arn
      DependsOn: LandingBucketRouteRawLambdaPermission

    # Permission to invoke the Lambda that routes files from the Landing bucket to the Raw buckets
    LandingBucketRouteRawLambdaPermission:
      Type: 'AWS::Lambda::Permission'
      Properties:
        FunctionName:
          Fn::GetAtt:
          - RouteRawLambdaFunction
          - Arn 
        Principal: 's3.amazonaws.com'
        Action: 'lambda:InvokeFunction'
        SourceAccount:
          Ref: AWS::AccountId
        SourceArn:
          Fn::Join:
            - ''
            - - 'arn:aws:s3:::'
              - ${self:custom.buckets.landing}

    ######################################################################
    # RAW BUCKETS
    ######################################################################
    
    # RAW PII BUCKET
    # S3 bucket that contains raw (csv) files containing PII data
    S3BucketRawPii:
      Type: AWS::S3::Bucket
      Properties:
        BucketName: ${self:custom.buckets.rawPii}
        NotificationConfiguration:
          LambdaConfigurations:
            - Event: s3:ObjectCreated:*
              Function:
                Fn::GetAtt:
                  - ExtractMetadataLambdaFunction
                  - Arn
      DependsOn: RawPiiBucketExtractMetadataLambdaPermission

    # Permission to invoke the Lambda that extracts metadata from the raw pii bucket
    RawPiiBucketExtractMetadataLambdaPermission:
      Type: 'AWS::Lambda::Permission'
      Properties:
        FunctionName:
          Fn::GetAtt:
            - ExtractMetadataLambdaFunction
            - Arn
        Principal: 's3.amazonaws.com'
        Action: 'lambda:InvokeFunction'
        SourceAccount:
          Ref: 'AWS::AccountId'
        SourceArn:
          Fn::Join:
            - ''
            - - 'arn:aws:s3:::'
              - ${self:custom.buckets.rawPii}

    # RAW HR BUCKET
    # S3 bucket that contains raw (csv) files containing HR data
    S3BucketRawHr:
      Type: AWS::S3::Bucket
      Properties:
        BucketName: ${self:custom.buckets.rawHr}
        NotificationConfiguration:
          LambdaConfigurations:
            - Event: s3:ObjectCreated:*
              Function:
                Fn::GetAtt:
                  - ExtractMetadataLambdaFunction
                  - Arn
      DependsOn: RawHrBucketExtractMetadataLambdaPermission

    # Permission to invoke the Lambda that extracts metadata from the raw hr bucket
    RawHrBucketExtractMetadataLambdaPermission:
      Type: 'AWS::Lambda::Permission'
      Properties:
        FunctionName:
          Fn::GetAtt:
            - ExtractMetadataLambdaFunction
            - Arn
        Principal: 's3.amazonaws.com'
        Action: 'lambda:InvokeFunction'
        SourceAccount:
          Ref: 'AWS::AccountId'
        SourceArn:
          Fn::Join:
            - ''
            - - 'arn:aws:s3:::'
              - ${self:custom.buckets.rawHr}

    # RAW REGULAR BUCKET
    # S3 bucket that contains raw (csv) files containing no security-related data
    S3BucketRawRegular:
      Type: AWS::S3::Bucket
      Properties:
        BucketName: ${self:custom.buckets.rawRegular}
        NotificationConfiguration:
          LambdaConfigurations:
            - Event: s3:ObjectCreated:*
              Function:
                Fn::GetAtt:
                  - ExtractMetadataLambdaFunction
                  - Arn
      DependsOn: RawRegularBucketExtractMetadataLambdaPermission

    # Permission to invoke the Lambda that extracts metadata from the raw regular bucket
    RawRegularBucketExtractMetadataLambdaPermission:
      Type: 'AWS::Lambda::Permission'
      Properties:
        FunctionName:
          Fn::GetAtt:
            - ExtractMetadataLambdaFunction
            - Arn
        Principal: 's3.amazonaws.com'
        Action: 'lambda:InvokeFunction'
        SourceAccount:
          Ref: 'AWS::AccountId'
        SourceArn:
          Fn::Join:
            - ''
            - - 'arn:aws:s3:::'
              - ${self:custom.buckets.rawRegular}

    ######################################################################
    # DELIVERY BUCKET
    ######################################################################
    
    # S3 bucket that contains the output of the datalake processing (csv)
    S3BucketDelivery:
      Type: AWS::S3::Bucket
      Properties:
        BucketName: ${self:custom.buckets.delivery}
        NotificationConfiguration:
          LambdaConfigurations:
            - Event: s3:ObjectCreated:*
              Function:
                Fn::GetAtt:
                  - ExtractMetadataLambdaFunction
                  - Arn
      DependsOn: DeliveryBucketExtractMetadataLambdaPermission

    # Permissions for the Lambda that extracts metadata from the raw and delivery buckets
    DeliveryBucketExtractMetadataLambdaPermission:
      Type: 'AWS::Lambda::Permission'
      Properties:
        FunctionName:
          Fn::GetAtt:
            - ExtractMetadataLambdaFunction
            - Arn
        Principal: 's3.amazonaws.com'
        Action: 'lambda:InvokeFunction'
        SourceAccount:
          Ref: 'AWS::AccountId'
        SourceArn:
          Fn::Join:
            - ''
            - - 'arn:aws:s3:::'
              - ${self:custom.buckets.delivery}

    ######################################################################
    # DISCOVERY BUCKETS
    ######################################################################
    
    # DISCOVERY PII BUCKET
    S3BucketDiscoveryPii:
      Type: AWS::S3::Bucket
      Properties:
        BucketName: ${self:custom.buckets.discoveryPii}
        # need to add policy to allow the cluster to read the bucket

    # DISCOVERY HR BUCKET
    S3BucketDiscoveryHr:
      Type: AWS::S3::Bucket
      Properties:
        BucketName: ${self:custom.buckets.discoveryHr}
        # need to add policy to allow the cluster to read the bucket

    # DISCOVERY REGULAR BUCKET
    S3BucketDiscoveryRegular:
      Type: AWS::S3::Bucket
      Properties:
        BucketName: ${self:custom.buckets.discoveryRegular}
        # need to add policy to allow the cluster to read the bucket

    ######################################################################
    # REFINED BUCKETS
    ######################################################################
    
    # REFINED PII BUCKET
    S3BucketRefinedPii:
      Type: AWS::S3::Bucket
      Properties:
        BucketName: ${self:custom.buckets.refinedPii}
        # need to add policy to allow the cluster to read the bucket

    # REFINED HR BUCKET
    S3BucketRefinedHr:
      Type: AWS::S3::Bucket
      Properties:
        BucketName: ${self:custom.buckets.refinedHr}
        # need to add policy to allow the cluster to read the bucket

    # REFINED REGULAR BUCKET
    S3BucketRefinedRegular:
      Type: AWS::S3::Bucket
      Properties:
        BucketName: ${self:custom.buckets.refinedRegular}
        # need to add policy to allow the cluster to read the bucket

    ######################################################################
    # DYNAMO TABLES
    ######################################################################

    FileMetadataDynamoTable:
      Type: 'AWS::DynamoDB::Table'
      Properties:
        AttributeDefinitions:
          -
            AttributeName: id
            AttributeType: S
        KeySchema:
          -
            AttributeName: id
            KeyType: HASH
        ProvisionedThroughput:
          ReadCapacityUnits: ${self:custom.dynamo.fileMetadata.readCapacity}
          WriteCapacityUnits: ${self:custom.dynamo.fileMetadata.writeCapacity}
        # NOTE: Must grant access to this TableName in iamRoleStatements section
        TableName: ${self:custom.dynamo.fileMetadata.name}

    ProcessMetadataDynamoTable:
      Type: 'AWS::DynamoDB::Table'
      Properties:
        AttributeDefinitions:
          -
            AttributeName: id
            AttributeType: S
        KeySchema:
          -
            AttributeName: id
            KeyType: HASH
        ProvisionedThroughput:
          ReadCapacityUnits: ${self:custom.dynamo.processMetadata.readCapacity}
          WriteCapacityUnits: ${self:custom.dynamo.processMetadata.writeCapacity}
        # NOTE: Must grant access to this TableName in iamRoleStatements section
        TableName: ${self:custom.dynamo.processMetadata.name}

    ######################################################################
    # SECRETS
    ######################################################################
    
    # STUFF NEEDED FOR SECRETS TO WORK - DO NOT MODIFY!!!
    AppKey: ${file(./serverless-resource-appkey.yml)}
    SecretsBucket:
      Type: AWS::S3::Bucket
      Properties:
        BucketName: ${self:custom.secretsBucket}
        VersioningConfiguration:
          Status: Enabled
        LoggingConfiguration:
          DestinationBucketName:
            Fn::ImportValue:
              AppSecretLoggingBucket
          LogFilePrefix: logs-${self:service}-${self:provider.stage}
    SecretsBucketPolicy: ${file(./serverless-resource-secretsbucketpolicy.yml)}

  ######################################################################
  # OUTPUTS
  ######################################################################

  Outputs:
    KmsKeyId:
      Description: KMS key id used to encrypt Github token
      Value:
        Ref: AppKey
    SecretsBucket:
      Description: Bucket to store secrets managed by MotherHen
      Value:
        Ref: SecretsBucket

